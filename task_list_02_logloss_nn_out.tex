% !TEX root = main.tex

%%%-------------------------------------------
\section{Что выплёвывает нейросеть} 

\epigraph{Плюют в душу обычно те, кому не удалось в неё влезть.}{\textit{Пацанский паблик категории Б}}

%%%-------------------------------------------
\begin{problem}{(про сигмоиду)}
Любую $s$-образную функцию называют сигмоидой. Наиболее сильно прославилась под таким названием функция $f(t) = \frac{e^t}{1 + e^t}.$ Слава о ней добралась до Маши и теперь она хочет немного поисследовать её свойства. 

\begin{enumerate}
	\item Что происходит при $t \to +\infty$? А при $t \to -\infty$?
	\item Как связаны между собой $f(t)$ и  $f(-t)$?
	\item Как связаны между собой $f'(t)$ и  $f'(-t)$?
	\item Как связаны между собой $f(t)$ и $f'(t)$? 
	\item Найдите $f(0)$, $f'(0)$ и $\ln f(0)$.
	\item Найдите обратную функцию $f^{-1}(t)$
	\item Как связаны между собой $\frac{d\ln f(t)}{dt}$ и $f(-t)$?
	\item Постройте графики функций $f(t)$ и $f'(t)$.
	\item Говорят, что сигмоида --- это гладкий аналог единичной ступеньки. Попробуйте построить на компьютере графики $f(t), f(10\cdot t), f(100\cdot t), f(1000\cdot t)$. Как они себя ведут? 
	\end{enumerate}
\end{problem} 

%%%-------------------------------------------
\begin{problem}{(про $\logloss$)}
	У Маши три наблюдения, первое наблюдение --- кит, остальные --- муравьи. Киты кодируются $y_i = 1$, муравьи --- $y_i = 0$.  В качестве регрессоров Маша берёт номера наблюдений $x_i = i$. После этого Маша оценивает логистическую регрессию с константой. В качестве функции потерь используются логистические потери. 
	
	\begin{enumerate}
		\item Выпишите для данной задачи функцию потерь, которую минимизирует Маша.
		\item При каких оценках коэффициентов логистической регрессии эта функция достигает своего минимума?
	\end{enumerate}
\end{problem}

%%%-------------------------------------------
\begin{problem}{(про $\softmax$)}
	Маша чуть внимательнее присмотрелась к своему третьему наблюдению и поняла, что это не кит, а бобёр. Теперь ей нужно решать задачу классификации на три класса. Она решил использовать для этого нейросеть с softmax-слоем на выходе. 
	
	Маша уже обучила нейронную сетку и хочет построить прогнозы для двух наблюдений. Слой, который находится перед $\softmax$ выдал для этих двух наблюдений следующий результат: $1, -2, 0$ и $0.5, -1, 0$.
	
	\begin{enumerate}
		\item Чему равны вероятности получить кита, муравья и бобра для этих двух наблюдений? 
		
		\item Пусть первым был кит, а вторым бобёр.  Чему будет равна $\logloss$-ошибка? 
		
		\item Пусть у Маши есть два класса. Она хочет выучить нейросеть. Она может учить нейронку с одним выходом и сигмоидой в качестве функции активации либо нейронку с двумя выходами и $\softmax$ в качестве функции активации. Как выходы этих двух нейронок взаимосвязаны между собой? 
		
		\item  Объясните, почему $\softmax$  считают сглаженным вариантом максимума.
	\end{enumerate}
\end{problem}

% \begin{sol} 
% В решении нарисовать изокванты
% http://www.johndcook.com/blog/2010/01/13/soft-maximum/

% Чтобы найти максимум мы обычно используем функцию $f(x,y) = \max(x,y)$. Давайте нарисуем линии уровня такой функции. Они будут острыми 

% \todo[inline]{Картинка}

% Теперь рассмотрим мягкий максимум $f(x, y) = e^x$


% % [1,−2,0]→[e1,e−2,e0]=[2.71,0.14,1]→[0.7,0.04,0.26]
% % [0.5,−1,0]→[e0.5,e−1,e0]=[1.65,0.37,1]→[0.55,0.12,0.33]
% \end{sol} 

%%%-------------------------------------------
\begin{problem}{(про разные выходы)}
Та, в чьих руках находится лёрнинг, решила немного поэкспериментировать с выходами из своей сетки. 

\begin{enumerate}
	\item  Для начала Маша решила, что хочет решать задачу классификации на два класса и получать на выходе вероятность принадлежности к первому. Что ей надо сделать с последним слоем сетки? 
	
	\item  Теперь Маша хочет решать задачу классификации на $K$ классов. Что ей делать с последним слоем? 
	
	\item  Новые вводные! Маша хочет спрогнозировать рейтинг фильма на "Кинопоиске". Он измеряется по шкале от $0$ до $10$ и принимает любое непрерывное значение. Как Маша может приспособить для этого свою нейронку? 
	
	\item У Маши есть куча новостей. Каждая новость может быть спортивной, политической или экономической. Иногда новость может относится сразу к нескольким категориям. Как Маше собрать нейросетку для решения этой задачи?  Как будет выглядеть при этом функция ошибки? 
	
	\item  У Маши есть картинки с уточками и чайками. Маша хочет научить нейросеть искать на картинке птицу, обводить её в прямоугольник (bounding box), а затем классифицировать то, что попало в прямоугольник. Как должен выглядеть выход из такой нейросети? Как должна выглядеть функция потерь? 
	
	\item  Маша задумалась, как можно спрогнозировать число людей в кафе так, чтобы на выходе сетка всегда прогнозировала целое число. Надо ли как-то при этом менять функцию потерь? 
	
	\textbf{Hint:} вспомните про пуассоновскую регрессию.
	% \item[f)] Пункт с регрессией и весами из денег 
\end{enumerate}
\end{problem}
